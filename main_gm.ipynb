{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.math.uwaterloo.ca/~hwolkowi/matrixcookbook.pdf\n",
    "# !pip install --upgrade --user ase\n",
    "# !pip install ipywidgets \n",
    "# !pip install ipympl\n",
    "# !conda install nglview -c conda-forge -y\n",
    "# !pip install --upgrade --user asap3\n",
    "# !pip install nglview\n",
    "# !pip install scikit-learn\n",
    "# !pip install scipy\n",
    "# !pip install sgdml\n",
    "# !pip install sgdml[ase]\n",
    "# !pip install sgdml[torch]\n",
    "# !conda install -c conde-forge kimpy openkim-models\n",
    "# !jupyter-nbextension enable nglview --py --sys-prefix\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from utils import *\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Process "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate normal distribution\n",
    "\n",
    "\n",
    "$$\n",
    "\\mathcal{N}(\\mu, \\sigma^2)\n",
    "$$\n",
    "\n",
    "$$\n",
    "p(x \\mid \\mu, \\sigma) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp{ \\left( -\\frac{(x - \\mu)^2}{2\\sigma^2}\\right)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def univariate_normal(x, mean, variance):\n",
    "    \"\"\"pdf of the univariate normal distribution.\"\"\"\n",
    "    return ((1. / np.sqrt(2 * np.pi * variance)) * \n",
    "            np.exp(-(x - mean)**2 / (2 * variance)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up plot\n",
    "univariate_plot(univariate_normal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate normal distribution\n",
    "\n",
    "$$\n",
    "p(\\mathbf{x} \\mid \\mathbf{\\mu}, \\Sigma) = \\frac{1}{\\sqrt{(2\\pi)^d \\lvert\\Sigma\\rvert}} \\exp{ \\left( -\\frac{1}{2}(\\mathbf{x} - \\mathbf{\\mu})^T \\Sigma^{-1} (\\mathbf{x} - \\mathbf{\\mu}) \\right)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathcal{N}(\\mathbf{\\mu}, \\Sigma)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multivariate_normal(x, d, mean, covariance):\n",
    "    \"\"\"pdf of the multivariate normal distribution.\"\"\"\n",
    "    x_m = x - mean\n",
    "    return (1. / (np.sqrt((2 * np.pi)**d * np.linalg.det(covariance))) * \n",
    "            np.exp(-(np.linalg.solve(covariance, x_m).T.dot(x_m)) / 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D Multivariate normal distribution\n",
    "$$\n",
    "\\mathcal{N}\\left(\n",
    "\\begin{bmatrix}\n",
    "0 \\\\\n",
    "0\n",
    "\\end{bmatrix}, \n",
    "\\begin{bmatrix}\n",
    "1 & 0 \\\\\n",
    "0 & 1 \n",
    "\\end{bmatrix}\\right)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathcal{N}\\left(\n",
    "\\begin{bmatrix}\n",
    "0 \\\\\n",
    "1\n",
    "\\end{bmatrix}, \n",
    "\\begin{bmatrix}\n",
    "1 & 0.8 \\\\\n",
    "0.8 & 1\n",
    "\\end{bmatrix}\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "\n",
    "multivariate_plot(multivariate_normal, nb_of_x=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Marginal and Conditional normal distributions\n",
    "\n",
    "If both $\\mathbf{x}$ and $\\mathbf{y}$ are [jointly normal](https://en.wikipedia.org/wiki/Multivariate_normal_distribution#Joint_normality) random vectors defined as:\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "\\mathbf{x} \\\\\n",
    "\\mathbf{y} \n",
    "\\end{bmatrix}\n",
    "\\sim\n",
    "\\mathcal{N}\\left(\n",
    "\\begin{bmatrix}\n",
    "\\mu_{\\mathbf{x}} \\\\\n",
    "\\mu_{\\mathbf{y}}\n",
    "\\end{bmatrix},\n",
    "\\begin{bmatrix}\n",
    "A & C \\\\\n",
    "C^T & B\n",
    "\\end{bmatrix}\n",
    "\\right)\n",
    "= \\mathcal{N}(\\mu, \\Sigma)\n",
    ", \\qquad \n",
    "\\Sigma^{-1} = \\Lambda = \n",
    "\\begin{bmatrix}\n",
    "\\tilde{A} & \\tilde{C} \\\\\n",
    "\\tilde{C}^T & \\tilde{B}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "The [conditional distribution](https://en.wikipedia.org/wiki/Conditional_probability_distribution) of $\\mathbf{x}$ given $\\mathbf{y}$ is defined as:\n",
    "\n",
    "$$\n",
    "p(\\mathbf{x} \\mid \\mathbf{y}) = \\mathcal{N}(\\mu_{x|y}, \\Sigma_{x|y})\n",
    "$$\n",
    "\n",
    "With:\n",
    "$$\\begin{split}\n",
    "\\Sigma_{x|y} & = A - CB^{-1}C^\\top = \\tilde{A}^{-1} \\\\\n",
    "\\mu_{x|y} & = \\mu_x + CB^{-1}(\\mathbf{y}-\\mu_y)\n",
    "\\end{split}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proof\n",
    "\n",
    "$\n",
    "\\begin{split}\n",
    "p(x_1, x_2) = exp\n",
    "\\left[\n",
    "-\\frac{1}{2}\n",
    "\\begin{pmatrix}\n",
    "x_1 - \\mu_1 \\\\ \n",
    "x_2 - \\mu_2\n",
    "\\end{pmatrix}^T\n",
    "\\begin{pmatrix}\n",
    "\\Sigma_{11} & \\Sigma_{12} \\\\ \n",
    "\\Sigma_{21} & \\Sigma_{22}\n",
    "\\end{pmatrix}^{-1}\n",
    "\\begin{pmatrix}\n",
    "x_1 - \\mu_1 \\\\ \n",
    "x_2 - \\mu_2\n",
    "\\end{pmatrix}\n",
    "\\right]\n",
    "\\end{split}\n",
    "$\n",
    "\n",
    "By using thr following idendty:\n",
    "\n",
    "$\n",
    "\\begin{split}\n",
    "M^{-1}=\n",
    "\\begin{pmatrix}\n",
    "A & B \\\\ \n",
    "C & D\n",
    "\\end{pmatrix}^{-1}=\n",
    "\\begin{pmatrix}\n",
    "I & 0 \\\\ \n",
    "-C^{-1}C & I\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    "(M/D)^{-1} & 0 \\\\ \n",
    "0 & D^{-1}\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    "I & -BD^{-1} \\\\ \n",
    "0 & I\n",
    "\\end{pmatrix}\n",
    "\\end{split}\n",
    "$\n",
    "\n",
    "We obtainig the folowing:\n",
    "\n",
    "$\n",
    "\\begin{pmatrix}\n",
    "x_1 - \\mu_1 \\\\ \n",
    "x_2 - \\mu_2\n",
    "\\end{pmatrix}^T\n",
    "\\begin{pmatrix}\n",
    "\\Sigma_{11} & \\Sigma_{12} \\\\ \n",
    "\\Sigma_{21} & \\Sigma_{22}\n",
    "\\end{pmatrix}^{-1}\n",
    "\\begin{pmatrix}\n",
    "x_1 - \\mu_1 \\\\ \n",
    "x_2 - \\mu_2\n",
    "\\end{pmatrix}=\n",
    "\\begin{pmatrix}\n",
    "x_1 - \\mu_1 \\\\ \n",
    "x_2 - \\mu_2\n",
    "\\end{pmatrix}^T\n",
    "\\begin{pmatrix}\n",
    "I & 0 \\\\ \n",
    "-\\Sigma_{22}^{-1} \\Sigma_{21} & I\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    "(\\Sigma/\\Sigma_{22})^{-1} & 0 \\\\ \n",
    "0 & \\Sigma_{22}^{-1}\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    "I & -\\Sigma_{12}\\Sigma_{22}^{-1} \\\\ \n",
    "0 & I\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    "x_1 - \\mu_1 \\\\ \n",
    "x_2 - \\mu_2\n",
    "\\end{pmatrix}\n",
    "$\n",
    "\n",
    "And finally:\n",
    "\n",
    "$\n",
    "(x_2 - \\mu_1 -\\Sigma_{12}\\Sigma_{22}^{-1}(x_2-\\mu_2))^T(\\Sigma/\\Sigma_{22})^{-1}(x_2 - \\mu_1 -\\Sigma_{12}\\Sigma_{22}^{-1}(x_2-\\mu_2)) + (x_2-\\mu_2)^T\\Sigma_22^{-1}(x_2-\\mu_2)\n",
    "$\n",
    "\n",
    "And plugin back into the first Eq:\n",
    "\n",
    "$\n",
    "\\begin{split}\n",
    "p(x_1, x_2) = exp\n",
    "\\left[\n",
    "-\\frac{1}{2}\n",
    "(x_2 - \\mu_1 -\\Sigma_{12}\\Sigma_{22}^{-1}(x_2-\\mu_2))^T(\\Sigma/\\Sigma_{22})^{-1}(x_2 - \\mu_1 -\\Sigma_{12}\\Sigma_{22}^{-1}(x_2-\\mu_2)) + (x_2-\\mu_2)^T\\Sigma_22^{-1}(x_2-\\mu_2)\n",
    "\\right]\n",
    "\\end{split}\n",
    "$\n",
    "$\n",
    "\\begin{split}\n",
    "p(x_1, x_2) = exp\n",
    "\\left[\n",
    "-\\frac{1}{2}\n",
    "(x_2 - \\mu_1 -\\Sigma_{12}\\Sigma_{22}^{-1}(x_2-\\mu_2))^T(\\Sigma/\\Sigma_{22})^{-1}(x_2 - \\mu_1 -\\Sigma_{12}\\Sigma_{22}^{-1}(x_2-\\mu_2))\n",
    "\\right] \\cdot\n",
    "exp\n",
    "\\left[\n",
    "-\\frac{1}{2}\n",
    "(x_2-\\mu_2)^T\\Sigma_22^{-1}(x_2-\\mu_2)\n",
    "\\right]\n",
    "\\end{split}\n",
    "$\n",
    "\n",
    "and from the axiom of probability we obtain the follwoing equlaity:\n",
    "\n",
    "$\n",
    "\\begin{split}\n",
    "p(x_1, x_2) = p(x_1|x_2)p(x_2)= exp\n",
    "\\left[\n",
    "-\\frac{1}{2}\n",
    "(x_2 - \\mu_1 -\\Sigma_{12}\\Sigma_{22}^{-1}(x_2-\\mu_2))^T(\\Sigma/\\Sigma_{22})^{-1}(x_2 - \\mu_1 -\\Sigma_{12}\\Sigma_{22}^{-1}(x_2-\\mu_2))\n",
    "\\right] \\cdot\n",
    "exp\n",
    "\\left[\n",
    "-\\frac{1}{2}\n",
    "(x_2-\\mu_2)^T\\Sigma_22^{-1}(x_2-\\mu_2)\n",
    "\\right] = \n",
    "exp\n",
    "\\left[\n",
    "-\\frac{1}{2}\n",
    "(x_2 - \\mu_1 -\\Sigma_{12}\\Sigma_{22}^{-1}(x_2-\\mu_2))^T(\\Sigma/\\Sigma_{22})^{-1}(x_2 - \\mu_1 -\\Sigma_{12}\\Sigma_{22}^{-1}(x_2-\\mu_2))\n",
    "\\right] \\cdot\n",
    "p(x_2)\n",
    "\\end{split} \\\\ \n",
    "\\Rightarrow p(x_1|x_2) = exp\n",
    "\\left[\n",
    "-\\frac{1}{2}\n",
    "(x_2 - \\mu_1 -\\Sigma_{12}\\Sigma_{22}^{-1}(x_2-\\mu_2))^T(\\Sigma/\\Sigma_{22})^{-1}(x_2 - \\mu_1 -\\Sigma_{12}\\Sigma_{22}^{-1}(x_2-\\mu_2))\n",
    "\\right] \\\\\n",
    "\\mu_{1|2} = \\mu_1 -\\Sigma_{12}\\Sigma_{22}^{-1}(x_2-\\mu_2)\n",
    "\\Sigma_{1|2} = (\\Sigma/\\Sigma_{22})=\\Sigma_{11}-\\Sigma_{12}\\Sigma_{22}^{-1}\\Sigma_{21}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "condition_plot(nb_of_x=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Process\n",
    "Gaussian process (GP) Is a method predicting $y^*$ for a given $x^*$ and getting: $y_i=f(x_i )$. \n",
    "GP assumes that p(f(x_1),...,f(x_N  )) is jointly Gaussian, i.e., the value of a new point m is defined as a multidimensional gaussian with $\\mu(x)$ and $\\Sigma(x)$, where $\\Sigma(x)$ is calculated as $\\Sigma_{ij}=k(x_i,x_j)$, and $k$ is the kernel function.<br/>\n",
    "Which can be regarded as a \"distance\" function which defines how strongly the value f(x_i) is coupled to point f(x_j). \n",
    "When trying to predict a new point x^* we use prior data points, calculating the new kernel values, and finally obtaining the following new multidimensional Gaussian distribution:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{pmatrix}\n",
    "f \\\\ \n",
    "f^*\n",
    "\\end{pmatrix}~\n",
    "\\mathcal{N}\n",
    "\\begin{pmatrix}\n",
    "\\begin{pmatrix}\n",
    "\\mu \\\\ \n",
    "\\mu^*\n",
    "\\end{pmatrix},\n",
    "\\begin{pmatrix}\n",
    "k & k^*\\\\ \n",
    "{k^{*}}^{T} & k^{**}\n",
    "\\end{pmatrix}\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "<br/>\n",
    "$f$ - Vector of all observed $y_i$ values, $f=y_i=f(x_i)$.<br/>\n",
    "$f^*$ - Prediction function for point $x^*$, $f^*=y^*=f(x^*)$.<br/>\n",
    "$\\mu$ - Vector of all observed mean values.<br/>\n",
    "$\\mu^*$- Mean values for the prediction for x^*. <br/>\n",
    "$k$ - Covariance matrix of all observed points<br/>\n",
    "$k^*$ - Kernel vector $k^*=k(x^*,x_i )$<br/>\n",
    "$k^{**}$ - Self kernel vector $k^{**}=k(x^*,x^* )$<br/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying the Conditional \n",
    "$$f(x^*)=\\mu^* +{{k}^{*}}^{T}  k^{-1}(y-\\mu)$$ <br/>\n",
    "For simplicity, we can define the mean values to be zero<br/>\n",
    "$$f(x^*) ={k^*}^{T}k^{-1}y=\\sum_{i=1}^{N}\\alpha_ik(x_i, x^*)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Most Popular Kernal\n",
    "Here, we will use the squared exponential kernel, also known as Gaussian kernel or RBF kernel\n",
    "$$\n",
    "\\kappa(\\mathbf{x}_i,\\mathbf{x}_j) = \\sigma_f^2 \\exp\\left(-\\frac{1}{2l^2}\n",
    "  (\\mathbf{x}_i - \\mathbf{x}_j)^T\n",
    "  (\\mathbf{x}_i - \\mathbf{x}_j)\\right)\\tag{10}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://juanitorduz.github.io/gaussian_process_reg/\n",
    "# http://krasserm.github.io/2018/03/19/gaussian-processes/\n",
    "def kernel(X1, X2, l=1.0, sigma_f=1.0):\n",
    "    '''\n",
    "    Isotropic squared exponential kernel. Computes\n",
    "    a covariance matrix from points in X1 and X2.\n",
    "\n",
    "    Args:\n",
    "        X1: Array of m points (m x d).\n",
    "        X2: Array of n points (n x d).\n",
    "\n",
    "    Returns:\n",
    "        Covariance matrix (m x n).\n",
    "    '''\n",
    "    sqdist = np.sum(X1 ** 2, 1).reshape(-1, 1) + np.sum(X2 ** 2, 1) - 2 * np.dot(X1, X2.T)\n",
    "    return sigma_f ** 2 * np.exp(-0.5 / l ** 2 * sqdist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Conditional on A Nosey Dataset\n",
    "If we have a training dataset with noisy function values $\\mathbf{y} = \\mathbf{f} + \\boldsymbol\\epsilon$ where noise $\\boldsymbol\\epsilon \\sim \\mathcal{N}(\\mathbf{0}, \\sigma_y^2 \\mathbf{I})$ is independently added to each observation then the predictive distribution is given by\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "p(\\mathbf{f}_* \\lvert \\mathbf{X}_*,\\mathbf{X},\\mathbf{y}) &= \\mathcal{N}(\\mathbf{f}_* \\lvert \\boldsymbol{\\mu}_*, \\boldsymbol{\\Sigma}_*) \\\\\n",
    "\\boldsymbol{\\mu_*} &= \\mathbf{K}_*^T \\mathbf{K}_y^{-1} \\mathbf{y} \\\\\n",
    "\\boldsymbol{\\Sigma_*} &= \\mathbf{K}_{**} - \\mathbf{K}_*^T \\mathbf{K}_y^{-1} \\mathbf{K}_*\n",
    "\\end{align*}\n",
    "$$\n",
    "where $\\mathbf{K}_y = \\mathbf{K} + \\sigma_y^2\\mathbf{I}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def posterior_predictive(X_s, X_train, Y_train, l=1.0, sigma_f=1.0, sigma_y=1e-8):\n",
    "    '''\n",
    "    Computes the suffifient statistics of the GP posterior predictive distribution\n",
    "    from m training data X_train and Y_train and n new inputs X_s.\n",
    "\n",
    "    Args:\n",
    "        X_s: New input locations (n x d).\n",
    "        X_train: Training locations (m x d).\n",
    "        Y_train: Training targets (m x 1).\n",
    "        l: Kernel length parameter.\n",
    "        sigma_f: Kernel vertical variation parameter.\n",
    "        sigma_y: Noise parameter.\n",
    "\n",
    "    Returns:\n",
    "        Posterior mean vector (n x d) and covariance matrix (n x n).\n",
    "    '''\n",
    "    K = kernel(X_train, X_train, l, sigma_f) + sigma_y ** 2 * np.eye(len(X_train))\n",
    "    K_s = kernel(X_train, X_s, l, sigma_f)\n",
    "    K_ss = kernel(X_s, X_s, l, sigma_f) + 1e-8 * np.eye(len(X_s))\n",
    "    K_inv = inv(K)\n",
    "\n",
    "\n",
    "    alphas = K_inv.dot(Y_train)\n",
    "    mu_s = K_s.T.dot(alphas)\n",
    "\n",
    "\n",
    "    cov_s = K_ss - K_s.T.dot(K_inv).dot(K_s)\n",
    "\n",
    "    return mu_s, cov_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "noise = 0.1\n",
    "x = [-3, -2 , -1,  1, 2 , 3, 4]\n",
    "def f(x):\n",
    "    func = np.exp(np.sin(x))\n",
    "    return func\n",
    "    \n",
    "gaussian_process(x, f, noise, posterior_predictive, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "noise = 0.1\n",
    "kernal = ConstantKernel(1.0) * RBF(length_scale=1.0)\n",
    "\n",
    "gaussian_process_interactive(f, noise, kernal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GP Force Field \n",
    "a straightforward formulation of a vector-valued estimator\n",
    "takes the form:\n",
    "$$\n",
    "\\mathbf{\\hat{f}}=\\begin{bmatrix}\\hat{f}_1(x), \\dots, \\hat{f}_N\\end{bmatrix}^{T}\n",
    "$$\n",
    "$\\mathbf{\\hat{f}}: \\mathbb{R}^N\\rightarrow\\mathbb{R}^N$ where each component: ${\\hat{f}_i}: \\mathbb{R}^N\\rightarrow\\mathbb{R}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "from ase_utils import *\n",
    "\"\"\"Demonstrates molecular dynamics with constant temperature.\"\"\"\n",
    "\n",
    "\n",
    "a = 3.519\n",
    "atoms_type = 'Ni'\n",
    "atoms = Atoms([Atom(atoms_type, (0, 0, 0)), \n",
    "               Atom(atoms_type, (0, a/2, a/2)),\n",
    "               Atom(atoms_type, (a/2, 0, a/2)),\n",
    "               Atom(atoms_type, (a/2, a/2, 0))])\n",
    "atoms.set_cell([a, a, a])\n",
    "atoms.set_pbc(True)\n",
    "atoms = atoms*2\n",
    "atoms_copy = atoms.copy()\n",
    "\n",
    "ngl.view_ngl(atoms, w=500, h=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ase.calculators.emt import EMT\n",
    "from ase.calculators.kim.kim import KIM\n",
    "T = 300  # Kelvin\n",
    "# Describe the interatomic interactions with the Effective Medium Theory\n",
    "# atoms.calc = EMT()\n",
    "atoms.calc = KIM(\"EAM_Dynamo_MishinFarkasMehl_1999_Ni__MO_400591584784_005\")\n",
    "# Set the momenta corresponding T\n",
    "MaxwellBoltzmannDistribution(atoms, T * 4 * units.kB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A molecular dynamics object will operate on the atoms by moving them according to their forces - \n",
    "# it integrates Newton’s second law numerically\n",
    "# # Room temperature simulation\n",
    "dyn = Langevin(atoms, 1 * units.fs, 2*T * units.kB, 0.002)\n",
    "dyn.attach(printenergy(atoms), interval=500)\n",
    "# We also want to save the positions of all atoms after every 100th time step.\n",
    "traj = Trajectory('reference.traj', 'w', atoms)\n",
    "dyn.attach(traj.write, interval=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now run the dynamics\n",
    "steps = 30000 - 1\n",
    "dyn.run(steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj = Trajectory('reference.traj', 'r', atoms)\n",
    "ngl.view_ngl(traj, w=500, h=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of mapping to scalar outputs, we can alternatively model the covariance\n",
    "function as a matrix $k : \\chi × \\chi → \\mathbb{R}^N\\rightarrow\\mathbb{R}^{N\\times N}$ that expresses the interaction among\n",
    "multiple output components. Together with a vector-valued mean function $\\mu : \\chi →\n",
    "\\mathbb{R}^N$ , we can then sample realizations of vector-valued functions from the GP\n",
    "$$\n",
    "\\mathbf{\\hat{f}} ∼ \\mathcal{GP}\\begin{bmatrix}\\mathbf{\\mu(x)}, \\mathbf{k(x,x^{'})}\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### the navie approch:\n",
    "$$\n",
    "\\mathbf{\\hat{f}}=\\begin{bmatrix}\\hat{f}_1(x), \\dots, \\hat{f}_N\\end{bmatrix}^{T}\n",
    "$$\n",
    "$$\n",
    "\\hat{f}_i(x) = \\mathcal{GP}\\begin{bmatrix}\\mathbf{\\mu(x)_i}, \\mathbf{k(x,x^{'})_i}\\end{bmatrix}\n",
    "$$\n",
    "$$\n",
    "\\mathbf{\\hat{f}}=\\begin{bmatrix}\\hat{f}_1(x) \\\\ \\dots \\\\ \\hat{f}_N(x)\\end{bmatrix}\n",
    "=\\begin{bmatrix}\\mathcal{GP}\\begin{bmatrix}\\mathbf{\\mu(x)_1}, \\mathbf{k(x,x^{'})_1}\\end{bmatrix} \\\\ \n",
    "\\dots\n",
    "\\\\ \\mathcal{GP}\\begin{bmatrix}\\mathbf{\\mu(x)_N}, \\mathbf{k(x,x^{'})_N}\\end{bmatrix}\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj = Trajectory('reference.traj', 'r', atoms)\n",
    "start, every = 1, 20\n",
    "(x, y), (x_test, y_test) = md_dataset_split(traj, start, every)\n",
    "print(f'train points: {len(x)}')\n",
    "noise = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.gaussian_process.kernels import ConstantKernel, RBF\n",
    "kernal= ConstantKernel(1.0) * RBF(length_scale=1.0)\n",
    "gpr = GaussianProcessRegressor(kernel=kernal, alpha=noise**2)\n",
    "gpr.fit(x, y)\n",
    "plot_gpr(gpr, x, y, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ase.calculators.calculator import Calculator\n",
    "class GPRCalculator(Calculator):\n",
    "    implemented_properties = ['forces']\n",
    "\n",
    "    def __init__(self, gdr, *args, **kwargs):\n",
    "        super(GPRCalculator, self).__init__(*args, **kwargs)\n",
    "        self.gpr_model = gdr\n",
    "\n",
    "    def calculate(self, atoms=None, *args, **kwargs):\n",
    "        super(GPRCalculator, self).calculate(atoms, *args, **kwargs)\n",
    "        r = np.array(atoms.get_positions())\n",
    "        x = r.reshape([1, -1])\n",
    "        f = self.gpr_model.predict(x)\n",
    "        self.results = {'forces': f.reshape(-1, 3)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atoms = atoms_copy.copy()\n",
    "atoms.calc = GPRCalculator(gpr)\n",
    "MaxwellBoltzmannDistribution(atoms, T * 2 * units.kB)\n",
    "dyn = Langevin(atoms, 1 * units.fs, T * units.kB, 0.002)\n",
    "steps = 30000\n",
    "traj = Trajectory('moldyn_gdr.traj', 'w', atoms)\n",
    "dyn.attach(traj.write, interval=1)\n",
    "dyn.run(steps)\n",
    "traj = Trajectory('moldyn_gdr.traj', 'r', atoms)\n",
    "ngl.view_ngl(traj, w=500, h=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### some tricks\n",
    "##### change the kernal:\n",
    "##### The Matérn kernel\n",
    "For our application, we considered a subclass from the parametric\n",
    "Matérn family (22–24) of (isotropic) kernel functions\n",
    "$$\n",
    "k: C_{\\mu=n+\\frac{1}{2}}(d)=exp{-\\frac{\\sqrt{2\\nu}d}{\\sigma}}P_{n}(d)\n",
    "$$\n",
    "$$\n",
    "P_n(d)=\\sum_{k=0}^{n}{\\frac{(n+k)!}{(2n)!}}\\begin{pmatrix}n\\\\k\\end{pmatrix}\\begin{pmatrix}\\frac{2\\sqrt{2\\nu}d}{\\sigma}\\end{pmatrix}^{n-k}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.gaussian_process.kernels import ConstantKernel, RBF, Matern\n",
    "kernal= Matern(length_scale=1.0, nu=2.5)\n",
    "gpr = GaussianProcessRegressor(kernel=kernal, alpha=noise**2)\n",
    "gpr.fit(x, y)\n",
    "plot_gpr(gpr, x, y, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atoms = atoms_copy.copy()\n",
    "atoms.calc = GPRCalculator(gpr)\n",
    "MaxwellBoltzmannDistribution(atoms, T * 2 * units.kB)\n",
    "dyn = Langevin(atoms, 1 * units.fs, T * units.kB, 0.002)\n",
    "steps = 30000\n",
    "traj = Trajectory('moldyn_gdr.traj', 'w', atoms)\n",
    "dyn.attach(traj.write, interval=1)\n",
    "dyn.run(steps)\n",
    "traj = Trajectory('moldyn_gdr.traj', 'r', atoms)\n",
    "ngl.view_ngl(traj, w=500, h=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### normalize y\n",
    "$$\n",
    "\\hat{y}_{train} = \\frac{y_{train}-E[y_{train}]}{\\sqrt{Var[y_{train}]}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernal= Matern(length_scale=1.0, nu=2.5)\n",
    "gpr = GaussianProcessRegressor(kernel=kernal, alpha=noise**2, normalize_y=True)\n",
    "gpr.fit(x, y)\n",
    "plot_gpr(gpr, x, y, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atoms = atoms_copy.copy()\n",
    "atoms.calc = GPRCalculator(gpr)\n",
    "MaxwellBoltzmannDistribution(atoms, T * 2 * units.kB)\n",
    "dyn = Langevin(atoms, 1 * units.fs, T * units.kB, 0.002)\n",
    "steps = 30000\n",
    "traj = Trajectory('moldyn_gdr.traj', 'w', atoms)\n",
    "dyn.attach(traj.write, interval=1)\n",
    "dyn.run(steps)\n",
    "traj = Trajectory('moldyn_gdr.traj', 'r', atoms)\n",
    "ngl.view_ngl(traj, w=500, h=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Roto-translational invariance\n",
    "Covariance functions remain valid under any transformation of their domain\n",
    ") is again a kernel function. A rather trivial implication is that all\n",
    "invariances of that input transformation are inherited, providing yet another opportunity\n",
    "to characterize the properties of the predictor [92].\n",
    "\n",
    "The so-called Coulomb matrix representation [7] goes one step further and represents\n",
    "each pair of nuclei in terms their Coulomb interaction instead of a simple distance. The\n",
    "Coulomb energy is the only nuclei-nuclei interaction term in the Hamiltonian and empirically a good starting point for inference about molecular properties [9]. We use a slight\n",
    "variation of this descriptor for our purpose, whereby atoms of different type interact on a\n",
    "normalized scale,\n",
    "$$\n",
    "D_{ij}=\\begin{matrix}\\lVert{r_i - r_j}\\lVert & i > j \\\\ 0 & i \\leq j \\end{matrix} \n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d, d_test = x_to_d(x), x_to_d(x_test)\n",
    "kernal= Matern(length_scale=1.0, nu=2.5)\n",
    "gpr = GaussianProcessRegressor(kernel=kernal, alpha=noise**2, normalize_y=True)\n",
    "gpr.fit(d, y)\n",
    "plot_gpr(gpr, d, y, d_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class iGPRCalculator(Calculator):\n",
    "    implemented_properties = ['forces']\n",
    "\n",
    "    def __init__(self, gdr, *args, **kwargs):\n",
    "        super(iGPRCalculator, self).__init__(*args, **kwargs)\n",
    "        self.gpr_model = gdr\n",
    "\n",
    "    def calculate(self, atoms=None, *args, **kwargs):\n",
    "        super(iGPRCalculator, self).calculate(atoms, *args, **kwargs)\n",
    "        r = np.array(atoms.get_positions())\n",
    "        x = r.reshape([1, -1])\n",
    "        f = self.gpr_model.predict(x_to_d(x))\n",
    "        self.results = {'forces': f.reshape(-1, 3)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atoms = atoms_copy.copy()\n",
    "atoms.calc = iGPRCalculator(gpr)\n",
    "MaxwellBoltzmannDistribution(atoms, T * 2 * units.kB)\n",
    "dyn = Langevin(atoms, 1 * units.fs, T * units.kB, 0.002)\n",
    "steps = 30000\n",
    "traj = Trajectory('moldyn_gdr.traj', 'w', atoms)\n",
    "dyn.attach(traj.write, interval=1)\n",
    "dyn.run(steps)\n",
    "traj = Trajectory('moldyn_gdr.traj', 'r', atoms)\n",
    "ngl.view_ngl(traj, w=500, h=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## incoding physical insight to the model\n",
    "In this setting, the corresponding RKHS is vector-valued and it has been shown\n",
    "that the representer theorem continues to hold. Each component of the kernel\n",
    "function $k_{ij}$ specifies a covariance between a pair of outputs $f_i(x)$ and $f_j(x)$, which\n",
    "makes it straightforward to impose linear constraints $g(x) = \\hat{G}[\\mathbf{f(x)}]$ on the GP\n",
    "prior\n",
    "$$\n",
    "\\mathbf{\\hat{g}(x)} ∼ \\mathcal{GP}\\begin{bmatrix}\\mathbf{\\hat{G}\\mu(x)}, \\hat{G}\\mathbf{k(x,x^{'})}{\\hat{G}'}^{T}\\end{bmatrix}\n",
    "\\\\\n",
    "for A, B\\; linear\\; operators\\\\\n",
    "Cov[Ax,By]=ACov[x,y]B^{T}\\\\\n",
    "E[Ax] = AE[x]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we aim to construct a GP that inherits the correct structure of a conservative\n",
    "force field to ensure integrability, so that the corresponding energy potential can\n",
    "be recovered from the same model. We start by considering, that the force field\n",
    "estimator $\\mathbf{\\hat{f}_{F}(x)}$ and the PES estimator $\\hat{f}_{E}(x)$ are related via some operator $\\hat{G}$ . To\n",
    "impose energy conservation, we require that the curl vanishes  for every\n",
    "input to the transformed energy model:\n",
    "$$\n",
    "\\nabla\\times \\hat{G}\\begin{bmatrix}\\hat{f}_E\\end{bmatrix} = \\mathbf{0}\n",
    "$$\n",
    "As expected, this is satisfied by the derivative operator Gˆ = ∇ or, in the case of\n",
    "energies and forces, the negative gradient operator\n",
    "$$\n",
    "\\mathbf{\\hat{f}_{F}(x)}=\\hat{G}\\begin{bmatrix}\\hat{f}_E\\end{bmatrix}=-\\nabla\\hat{f}_E\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since differentiation is a linear operator, the result is another GP with realizations $\\mathbf{f_F}: \\chi^{3N}\\rightarrow \\mathbb{R}^{3N}$\n",
    "$$\n",
    "\\mathbf{\\hat{f}_F(x)} ∼ \\mathcal{GP}\\begin{bmatrix}\\mathbf{-\\nabla\\mu(x)}, \\nabla_x\\mathbf{k(x,x^{'})}{ \\nabla_{x'}}^{T}\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\nabla\\mathbf{k}{ \\nabla}^{T}=Hess_x(k)\n",
    "$$\n",
    "$$\n",
    "\\begin{bmatrix}Hess_s(k)\\end{bmatrix}_{ij}=\\frac{\\partial^2 k}{\\partial x_i \\partial x_j}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Hessian kernel gives rise to the following gradient domain machine\n",
    "learning [88, 89] force model as the posterior mean of the corresponding GP:<br>\n",
    "he trained force field estimator collects the contributions of the\n",
    "partial derivatives 3N of all training points M to compile the prediction.\n",
    "It takes the form\n",
    "$$\n",
    "\\mathbf{\\hat{f}_F(x)}=\\sum_i^M{\\sum_j^{3N}{(\\mathbf{\\alpha_i})_j\\frac{\\partial}{\\partial x_j}\\nabla k(\\mathbf{x}, \\mathbf{x_i})}}\n",
    "$$\n",
    "    \n",
    "Because the trained model is a (fixed) linear combination of kernel functions,\n",
    "integration only affects the kernel function itself. The corresponding expression for\n",
    "the energy predictor\n",
    "$$\n",
    "\\mathbf{\\hat{f}_E(x)}=\\sum_i^M{\\sum_j^{3N}{(\\mathbf{\\alpha_i})_j\\frac{\\partial}{\\partial x_j} k(\\mathbf{x}, \\mathbf{x_i})}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Roto-translational invariance\n",
    "Covariance functions remain valid under any transformation of their domain $D : X → D,\n",
    "i.e. k(D(x),D(x′)) = k_D(x,x′)$ is again a kernel function.\n",
    "$$\n",
    "D_{ij}=\\begin{matrix}\\lVert{r_i - r_j}\\lVert & i > j \\\\ 0 & i \\leq j \\end{matrix} \n",
    "$$\n",
    "and under the chain rule:\n",
    "$$\n",
    "\\mathbf{k_F}=\\nabla_x k_D \\nabla_x^\\top = \\mathbf{J_D}^\\top(\\nabla_D k_D \\nabla_D^\\top)\\mathbf{J_D}\n",
    "$$\n",
    "where:\n",
    "$$\n",
    "\\nabla_x = \\begin{pmatrix}\\frac{\\partial}{\\partial x_1} \\\\ \\dots \\\\ \\frac{\\partial}{\\partial x_{3N}}\\end{pmatrix}=\n",
    "\\begin{pmatrix}\\frac{\\partial D_{11}}{\\partial x_1}\\frac{\\partial}{\\partial  D_{11}} +\n",
    "                \\frac{\\partial D_{12}}{\\partial x_1}\\frac{\\partial}{\\partial  D_{12}} + \n",
    "                \\dots\n",
    "                \\frac{\\partial D_{1N}}{\\partial x_1}\\frac{\\partial}{\\partial  D_{1N}} +\n",
    "                \\frac{\\partial D_{23}}{\\partial x_1}\\frac{\\partial}{\\partial  D_{23}} +\n",
    "                \\dots\n",
    "                \\frac{\\partial D_{NN}}{\\partial x_1}\\frac{\\partial}{\\partial  D_{NN}}\\\\\n",
    "                \\dots \\\\ \n",
    "                \\frac{\\partial D_{11}}{\\partial x_{3N}}\\frac{\\partial}{\\partial  D_{11}} +\n",
    "                \\frac{\\partial D_{12}}{\\partial x_{3N}}\\frac{\\partial}{\\partial  D_{12}} + \n",
    "                \\dots\n",
    "                \\frac{\\partial D_{1N}}{\\partial x_{3N}}\\frac{\\partial}{\\partial  D_{1N}} +\n",
    "                \\frac{\\partial D_{23}}{\\partial x_{3N}}\\frac{\\partial}{\\partial  D_{23}} +\n",
    "                \\dots\n",
    "                \\frac{\\partial D_{NN}}{\\partial x_{3N}}\\frac{\\partial}{\\partial  D_{NN}}\\end{pmatrix}=\n",
    "\\begin{pmatrix}\\frac{\\partial D_{11}}{\\partial x_1} &\n",
    "               \\frac{\\partial D_{12}}{\\partial x_1} &  \n",
    "               \\dots &\n",
    "               \\frac{\\partial D_{1N}}{\\partial x_1} &\n",
    "               \\frac{\\partial D_{23}}{\\partial x_1} & \n",
    "               \\dots &\n",
    "               \\frac{\\partial D_{NN}}{\\partial x_1} \\\\\n",
    "               \\dots & \\dots & \\dots & \\dots & \\dots & \\dots \\\\ \n",
    "               \\frac{\\partial D_{11}}{\\partial x_{3N}} & \n",
    "               \\frac{\\partial D_{12}}{\\partial x_{3N}} &  \n",
    "               \\dots &\n",
    "               \\frac{\\partial D_{1N}}{\\partial x_{3N}} &  \n",
    "               \\frac{\\partial D_{23}}{\\partial x_{3N}} & \n",
    "               \\dots &\n",
    "               \\frac{\\partial D_{NN}}{\\partial x_{3N}} \\end{pmatrix}\n",
    "               \\begin{pmatrix}\\frac{\\partial}{\\partial D_{11}} \\\\ \\dots \\\\ \\frac{\\partial}{\\partial D_{NN}}\\end{pmatrix}\n",
    "               =\\mathbf{J_D}^\\top\\nabla_D \\\\\n",
    "               \\\\\n",
    "\\mathbf{J_D}=\\begin{matrix}\\frac{\\mathbf{r_i} - \\mathbf{r_j} }{\\lVert{\\mathbf{r_i}  - \\mathbf{r_j}}\\lVert^3} & i > j \\\\ 0 & i \\leq j \\end{matrix} \n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sgdml.cli import _print_dataset_properties, _print_model_properties, _print_task_properties\n",
    "\n",
    "dataset_path = 'reference'\n",
    "dataset = from_traj(f'{dataset_path}.traj', overwrite=True)\n",
    "dataset_path = f'{dataset_path}.npz'\n",
    "# test = np.load('ethanol_dft.npz')\n",
    "_print_dataset_properties(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = 250\n",
    "n_valid = 1500\n",
    "file = all_script(dataset_path, n_train, n_valid, sigs=range(1, 100, 1), use_cg=False, use_torch=True)\n",
    "print(f'please run \\\"bash {file}\\\" from the terminal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'reference-unknown-train200-sym1.npz'\n",
    "traj = Trajectory('reference.traj', 'r', atoms)\n",
    "start, every = 10, 10\n",
    "plot_gdml(model_path, traj, start, every)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sgdml.intf.ase_calc import SGDMLCalculator\n",
    "from ase_utils import *\n",
    "from ase.optimize import QuasiNewton\n",
    "import gc\n",
    "model_path = 'reference-unknown-train100-sym1.npz'\n",
    "calc = SGDMLCalculator(model_path)\n",
    "atoms = atoms_copy.copy()\n",
    "atoms.set_calculator(calc)\n",
    "# set the momenta corresponding to T=300K\n",
    "MaxwellBoltzmannDistribution(atoms, T * units.kB)\n",
    "dyn = Langevin(atoms, 1 * units.fs, T * units.kB, 0.002, trajectory='moldyn_sgdml.traj')    \n",
    "dyn.attach(printenergy(atoms), interval=500)\n",
    "\n",
    "# now run the dynamics\n",
    "printenergy(atoms)\n",
    "dyn.run(30000)\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj = Trajectory('moldyn_sgdml.traj', 'r', atoms)\n",
    "ngl.view_ngl(traj, w=500, h=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For scalar output\n",
    "$$\n",
    "\\begin{bmatrix}f^*\\end{bmatrix}^{1\\times1} = \\begin{bmatrix}{k^*}^T\\end{bmatrix}^{1\\times M}\\begin{bmatrix}\\begin{bmatrix}K^{-1}\\end{bmatrix}^{M \\times M}\\begin{bmatrix}y\\end{bmatrix}^{M\\times 1}\\end{bmatrix}^{M\\times1}=\\sum_{i}^{M}\\alpha_i k(x_i,x^*)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For vector output\n",
    "$$\n",
    "\\begin{bmatrix}\\mathbf{f^*}\\end{bmatrix}^{3N\\times1} ={k^*}^{T}K^{-1}\\mathbf{f}=\\sum_i^M{\\sum_j^{3N}{(\\mathbf{\\alpha_i})_j\\frac{\\partial}{\\partial x_j}\\nabla k(\\mathbf{x}, \\mathbf{x_i})}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "K=\\nabla_{x} k(x,x') \\nabla_{x^{'}}^\\top = \n",
    "\\begin{pmatrix}\n",
    "\\begin{pmatrix}\\nabla_{x^{(1)}} k(x^{(1)},x^{(1)}) \\nabla_{x^{(1)}}^\\top\\end{pmatrix} & \\dots & \\begin{pmatrix}\\nabla_{x^{(M)}} k(x^{(M)},x^{(1)}) \\nabla_{x^{(1)}}^\\top\\end{pmatrix} \\\\\n",
    "\\dots & \\dots & \\dots \\\\\n",
    "\\begin{pmatrix}\\nabla_{x^{(M)}} k(x^{(M)},x^{(1)}) \\nabla_{x^{(1)}}^\\top\\end{pmatrix} & \\dots & \\begin{pmatrix}\\nabla_{x^{(M)}} k(x^{(M)},x^{(M)}) \\nabla_{x^{(M)}}^\\top\\end{pmatrix}\n",
    "\\end{pmatrix}\n",
    "\\\\\n",
    "\\nabla k(x^{(i)}, x^{(j)})\\nabla ^\\top=\\begin{bmatrix}\\frac{\\partial}{\\partial x^{(j)}_1 }\\nabla k(x^{(i)},x^{(j)}),\\dots,\\frac{\\partial}{\\partial x^{(j)}_{3N} }\\nabla k(x^{(i)},x^{(j)})\\end{bmatrix}^{3N\\times 3N}\n",
    "=\\begin{bmatrix}\\frac{\\partial}{\\partial x^{(j)}_1 }\\frac{\\partial}{\\partial x^{(i)}_{1}} k(x^{(i)},x^{(j)}) &\\dots & \\frac{\\partial}{\\partial x^{(j)}_{3N} }\\frac{\\partial}{\\partial x^{(i)}_{1}} k(x^{(i)},x^{(j)}) \\\\\n",
    "\\dots & \\dots & \\dots \\\\\n",
    "\\frac{\\partial}{\\partial x^{(j)}_1}\\frac{\\partial}{\\partial x^{(i)}_{3N}} k(x^{(i)},x^{(j)}) &\\dots & \\frac{\\partial}{\\partial x^{(j)}_{3N} }\\frac{\\partial}{\\partial x^{(i)}_{3N}} k(x^{(i)},x^{(j)})\n",
    "\\end{bmatrix}^{3N\\times 3N}\n",
    "\\\\\n",
    "\\begin{bmatrix}K\\end{bmatrix}^{M\\cdot3N\\times M\\cdot3N} \\;\n",
    "\\begin{bmatrix}\\mathbf{f}\\end{bmatrix}^{M\\cdot3N\\times 1}\n",
    "\\\\\n",
    "$$\n",
    "$$\n",
    "{k^*}^{T}\n",
    "=\\nabla_x k(x^{*}, x)\\nabla_{x^{'}} ^\\top \n",
    "=\n",
    "\\begin{bmatrix}\n",
    "\\begin{pmatrix}\\nabla_{x^*} k(x^{*}, x^{(1)})\\nabla_{x^{(1)}} ^\\top\\end{pmatrix} & \n",
    "\\dots & \n",
    "\\begin{pmatrix}\\nabla k(x^{*}, x^{(M)})\\nabla_{x^{(M)}} ^\\top\\end{pmatrix}\n",
    "\\end{bmatrix}^{3N\\times M\\cdot 3N}\n",
    "= \n",
    "\\begin{bmatrix}\n",
    "\\begin{pmatrix}\\frac{\\partial}{\\partial x^{(1)}_1 }\\nabla k(x^{*},x^{(1)}),\\dots,\\frac{\\partial}{\\partial x^{(1)}_{3N} }\\nabla k(x^{*},x^{(1)})\\end{pmatrix} & \n",
    "\\dots & \n",
    "\\begin{pmatrix}\\frac{\\partial}{\\partial x^{(M)}_1 }\\nabla k(x^{*},x^{(M)}),\\dots,\\frac{\\partial}{\\partial x^{(M)}_{3N} }\\nabla k(x^{*},x^{(M)})\\end{pmatrix}\n",
    "\\end{bmatrix}^{3N\\times M\\cdot 3N}\n",
    "\\\\\n",
    "\\\\\n",
    "\\begin{bmatrix}\\mathbf{f^*}\\end{bmatrix}^{3N\\times1} =\\begin{bmatrix}\\begin{bmatrix}{k^*}^{T}\\end{bmatrix}^{3N \\times M \\cdot 3N}\\begin{bmatrix}\\begin{bmatrix}K^{-1}\\end{bmatrix}^{M\\cdot 3N \\times M\\cdot 3N}\\begin{bmatrix}\\mathbf{f}\\end{bmatrix}^{M\\cdot 3N \\times 1}\\end{bmatrix}^{M \\cdot 3N \\times 1}\\end{bmatrix}^{3N\\times 1}\n",
    "\\\\\n",
    "\\begin{bmatrix}\\mathbf{f^*}\\end{bmatrix}^{3N\\times1} =\n",
    "{k^*}^{T}\n",
    "K^{-1}\n",
    "\\mathbf{f}=\n",
    "\\begin{pmatrix}\n",
    "\\begin{pmatrix}\\frac{\\partial}{\\partial x^{(1)}_1 }\\nabla k(x^{*},x^{(1)}),\\dots,\\frac{\\partial}{\\partial x^{(1)}_{3N} }\\nabla k(x^{*},x^{(1)})\\end{pmatrix} & \n",
    "\\dots & \n",
    "\\begin{pmatrix}\\frac{\\partial}{\\partial x^{(M)}_1 }\\nabla k(x^{*},x^{(M)}),\\dots,\\frac{\\partial}{\\partial x^{(M)}_{3N} }\\nabla k(x^{*},x^{(M)})\\end{pmatrix}\n",
    "\\end{pmatrix}\n",
    "\\underbrace{ K^{-1}\\mathbf{f}}_{\\alpha _{ij}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Matérn kernel\n",
    "For our application, we considered a subclass from the parametric\n",
    "Matérn family (22–24) of (isotropic) kernel functions\n",
    "$$\n",
    "k: C_{\\nu=n+\\frac{1}{2}}(d)=exp{-\\frac{\\sqrt{2\\nu}d}{\\sigma}}P_{n}(d)\n",
    "$$\n",
    "$$\n",
    "P_n(d)=\\sum_{k=0}^{n}{\\frac{(n+k)!}{(2n)!}}\\begin{pmatrix}n\\\\k\\end{pmatrix}\\begin{pmatrix}\\frac{2\\sqrt{2\\nu}d}{\\sigma}\\end{pmatrix}^{n-k}\n",
    "$$\n",
    "\n",
    "### The full kernel\n",
    "\n",
    "$$\n",
    "\\mathbf{k_F(x, x^{'})}=\\nabla k(x, x^{'})\\nabla ^\\top=\\begin{bmatrix}\\frac{\\partial}{\\partial x^{'}_1 }\\nabla k(x,x^{'}),\\dots,\\frac{\\partial}{\\partial x^{'}_{3N} }\\nabla k(x,x^{'})\\end{bmatrix}\n",
    "$$\n",
    "$$\n",
    "=\\begin{pmatrix}5(\\mathbf{x-x^{'}})(\\mathbf{x-x^{'}})^\\top-\\mathbb{1}\\sigma(\\sigma +\\sqrt{5}d))\\end{pmatrix}\\frac{5}{3\\sigma^{4}}exp\\begin{pmatrix}-\\frac{\\sqrt{5}d}{\\sigma}\\end{pmatrix}\n",
    "$$\n",
    "$$\n",
    "\\mathbf{k_F(x, x^{'})}\\in \\mathbb{R}^{3N \\times 3N}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathbf{k_E(x, x^{'})}=k(x, x^{'})\\nabla ^\\top\n",
    "=5(\\mathbf{x-x^{'}})(\\sigma+d)\\frac{5}{3\\sigma^{3}}exp\\begin{pmatrix}-\\frac{\\sqrt{5}d}{\\sigma}\\end{pmatrix}\n",
    "$$\n",
    "$$\n",
    "\\mathbf{k_E(x, x^{'})}\\in \\mathbb{R}^{1 \\times 3N}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matérn covariance derivatives\n",
    "$$\n",
    "k: C_{\\nu=n+\\frac{1}{2}}(d)=B(d)P_{n}(d)\n",
    "\\\\\n",
    "B(d) = exp{\\begin{pmatrix}-\\frac{\\sqrt{2\\nu}d}{\\sigma}\\end{pmatrix}}\n",
    "\\\\\n",
    "P_n(d)=\\sum_{k=0}^{n}{\\frac{(n+k)!}{(2n)!}}\\begin{pmatrix}n\\\\k\\end{pmatrix}\\begin{pmatrix}\\frac{2\\sqrt{2\\nu}d}{\\sigma}\\end{pmatrix}^{n-k}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial \\kappa}{\\partial x_i} = \\frac{\\partial P_n}{\\partial x_i}B + \\frac{\\partial B}{\\partial x_i}P_n\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial P_n}{\\partial x_i}=\\sum_{k=0}^n{\\frac{(n+k)!}{(2n)!}\\begin{pmatrix}n\\\\k\\end{pmatrix}\\frac{(n-k)(x_i -x^{'}_i)}{d^2}\\begin{pmatrix}\\frac{2\\sqrt{2\\nu}d}{\\sigma}\\end{pmatrix}^{n-k}}\\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial B}{\\partial x_i} =-\\frac{\\sqrt{2\\nu}(x_i -x^{'}_i)}{\\sigma d}exp{-\\frac{\\sqrt{2\\nu}d}{\\sigma}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial^2 \\kappa}{\\partial x_i \\partial x_j} = \n",
    "B\\frac{\\partial^2 P_n}{\\partial x_i \\partial x_j} +\n",
    "\\frac{\\partial B}{\\partial x_i}\\frac{\\partial P_n}{\\partial x_j} +\n",
    "\\frac{\\partial B}{\\partial x_j}\\frac{\\partial P_n}{\\partial x_i} +\n",
    "P_n\\frac{\\partial^2 B}{\\partial x_i \\partial x_j} \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{bmatrix}\\frac{\\partial^2 P_n}{\\partial x_i \\partial x_j}\\end{bmatrix}_{i\\ne j}=\n",
    "\\sum_{k=0}^{n}{\\frac{(n+k)!}{(2n)!}\\begin{pmatrix}n \\\\ k \\end{pmatrix}\n",
    "\\frac{(n-k-2)(n-k)(x_i -x^{'}_i)(x_j - x^{'}_j)}{d^4}\n",
    "\\begin{pmatrix}\\frac{2\\sqrt{2\\nu}d}{\\sigma}\\end{pmatrix}^{n-k}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{bmatrix}\\frac{\\partial^2 P_n}{\\partial x_i \\partial x_j}\\end{bmatrix}_{i=j}=\n",
    "\\sum_{k=0}^{n}{\\frac{(n+k)!}{(2n)!}\\begin{pmatrix}n \\\\ k \\end{pmatrix}\n",
    "\\frac{(n-k-2)(n-k)(x_i -x^{'}_i)^2}{d^4}\n",
    "\\begin{pmatrix}\\frac{2\\sqrt{2\\nu}d}{\\sigma}\\end{pmatrix}^{n-k}} + \\sum_{k=0}^n{\\frac{(n+k)!}{(2n)!}\\begin{pmatrix}n\\\\k\\end{pmatrix}\\frac{(n-k)}{d^2}\\begin{pmatrix}\\frac{2\\sqrt{2\\nu}d}{\\sigma}\\end{pmatrix}^{n-k}}\\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{bmatrix}\\frac{\\partial^2 B}{\\partial x_i \\partial x_j}\\end{bmatrix}_{i\\ne j} =\n",
    "\\frac{\\sqrt{2\\nu}(x_i-x^{'})(x_j-x^{'}_j)(\\sqrt{2\\nu} d+\\sigma)}{\\sigma^2d^3}\\exp{\\begin{pmatrix}-\\frac{\\sqrt{2\\nu}d}{\\sigma}\\end{pmatrix}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{bmatrix}\\frac{\\partial^2 B}{\\partial x_i \\partial x_j}\\end{bmatrix}_{i = j} =\n",
    "\\frac{\\sqrt{2\\nu}(x_i-x^{'})(x_j-x^{'}_j)(\\sqrt{2\\nu} d+\\sigma)}{\\sigma^2d^3}\\exp{\\begin{pmatrix}-\\frac{\\sqrt{2\\nu}d}{\\sigma}\\end{pmatrix}} - \\frac{\\sqrt{2\\nu}(x_i -x^{'}_i)}{\\sigma d}exp{\\begin{pmatrix}-\\frac{\\sqrt{2\\nu}d}{\\sigma}\\end{pmatrix}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
