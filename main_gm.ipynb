{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from utils import *\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Process "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate normal distribution\n",
    "\n",
    "\n",
    "$$\n",
    "\\mathcal{N}(\\mu, \\sigma^2)\n",
    "$$\n",
    "\n",
    "$$\n",
    "p(x \\mid \\mu, \\sigma) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp{ \\left( -\\frac{(x - \\mu)^2}{2\\sigma^2}\\right)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def univariate_normal(x, mean, variance):\n",
    "    \"\"\"pdf of the univariate normal distribution.\"\"\"\n",
    "    return ((1. / np.sqrt(2 * np.pi * variance)) * \n",
    "            np.exp(-(x - mean)**2 / (2 * variance)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up plot\n",
    "univariate_plot(univariate_normal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate normal distribution\n",
    "\n",
    "$$\n",
    "p(\\mathbf{x} \\mid \\mathbf{\\mu}, \\Sigma) = \\frac{1}{\\sqrt{(2\\pi)^d \\lvert\\Sigma\\rvert}} \\exp{ \\left( -\\frac{1}{2}(\\mathbf{x} - \\mathbf{\\mu})^T \\Sigma^{-1} (\\mathbf{x} - \\mathbf{\\mu}) \\right)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathcal{N}(\\mathbf{\\mu}, \\Sigma)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multivariate_normal(x, d, mean, covariance):\n",
    "    \"\"\"pdf of the multivariate normal distribution.\"\"\"\n",
    "    x_m = x - mean\n",
    "    return (1. / (np.sqrt((2 * np.pi)**d * np.linalg.det(covariance))) * \n",
    "            np.exp(-(np.linalg.solve(covariance, x_m).T.dot(x_m)) / 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D Multivariate normal distribution\n",
    "$$\n",
    "\\mathcal{N}\\left(\n",
    "\\begin{bmatrix}\n",
    "0 \\\\\n",
    "0\n",
    "\\end{bmatrix}, \n",
    "\\begin{bmatrix}\n",
    "1 & 0 \\\\\n",
    "0 & 1 \n",
    "\\end{bmatrix}\\right)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathcal{N}\\left(\n",
    "\\begin{bmatrix}\n",
    "0 \\\\\n",
    "1\n",
    "\\end{bmatrix}, \n",
    "\\begin{bmatrix}\n",
    "1 & 0.8 \\\\\n",
    "0.8 & 1\n",
    "\\end{bmatrix}\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "\n",
    "multivariate_plot(multivariate_normal, nb_of_x=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Marginal and Conditional normal distributions\n",
    "\n",
    "If both $\\mathbf{x}$ and $\\mathbf{y}$ are [jointly normal](https://en.wikipedia.org/wiki/Multivariate_normal_distribution#Joint_normality) random vectors defined as:\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "\\mathbf{x} \\\\\n",
    "\\mathbf{y} \n",
    "\\end{bmatrix}\n",
    "\\sim\n",
    "\\mathcal{N}\\left(\n",
    "\\begin{bmatrix}\n",
    "\\mu_{\\mathbf{x}} \\\\\n",
    "\\mu_{\\mathbf{y}}\n",
    "\\end{bmatrix},\n",
    "\\begin{bmatrix}\n",
    "A & C \\\\\n",
    "C^T & B\n",
    "\\end{bmatrix}\n",
    "\\right)\n",
    "= \\mathcal{N}(\\mu, \\Sigma)\n",
    ", \\qquad \n",
    "\\Sigma^{-1} = \\Lambda = \n",
    "\\begin{bmatrix}\n",
    "\\tilde{A} & \\tilde{C} \\\\\n",
    "\\tilde{C}^T & \\tilde{B}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "The [conditional distribution](https://en.wikipedia.org/wiki/Conditional_probability_distribution) of $\\mathbf{x}$ given $\\mathbf{y}$ is defined as:\n",
    "\n",
    "$$\n",
    "p(\\mathbf{x} \\mid \\mathbf{y}) = \\mathcal{N}(\\mu_{x|y}, \\Sigma_{x|y})\n",
    "$$\n",
    "\n",
    "With:\n",
    "$$\\begin{split}\n",
    "\\Sigma_{x|y} & = A - CB^{-1}C^\\top = \\tilde{A}^{-1} \\\\\n",
    "\\mu_{x|y} & = \\mu_x + CB^{-1}(\\mathbf{y}-\\mu_y)\n",
    "\\end{split}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proof\n",
    "\n",
    "$\n",
    "\\begin{split}\n",
    "p(x_1, x_2) = exp\n",
    "\\left[\n",
    "-\\frac{1}{2}\n",
    "\\begin{pmatrix}\n",
    "x_1 - \\mu_1 \\\\ \n",
    "x_2 - \\mu_2\n",
    "\\end{pmatrix}^T\n",
    "\\begin{pmatrix}\n",
    "\\Sigma_{11} & \\Sigma_{12} \\\\ \n",
    "\\Sigma_{21} & \\Sigma_{22}\n",
    "\\end{pmatrix}^{-1}\n",
    "\\begin{pmatrix}\n",
    "x_1 - \\mu_1 \\\\ \n",
    "x_2 - \\mu_2\n",
    "\\end{pmatrix}\n",
    "\\right]\n",
    "\\end{split}\n",
    "$\n",
    "\n",
    "By using thr following idendty:\n",
    "\n",
    "$\n",
    "\\begin{split}\n",
    "M^{-1}=\n",
    "\\begin{pmatrix}\n",
    "A & B \\\\ \n",
    "C & D\n",
    "\\end{pmatrix}^{-1}=\n",
    "\\begin{pmatrix}\n",
    "I & 0 \\\\ \n",
    "-C^{-1}C & I\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    "(M/D)^{-1} & 0 \\\\ \n",
    "0 & D^{-1}\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    "I & -BD^{-1} \\\\ \n",
    "0 & I\n",
    "\\end{pmatrix}\n",
    "\\end{split}\n",
    "$\n",
    "\n",
    "We obtainig the folowing:\n",
    "\n",
    "$\n",
    "\\begin{pmatrix}\n",
    "x_1 - \\mu_1 \\\\ \n",
    "x_2 - \\mu_2\n",
    "\\end{pmatrix}^T\n",
    "\\begin{pmatrix}\n",
    "\\Sigma_{11} & \\Sigma_{12} \\\\ \n",
    "\\Sigma_{21} & \\Sigma_{22}\n",
    "\\end{pmatrix}^{-1}\n",
    "\\begin{pmatrix}\n",
    "x_1 - \\mu_1 \\\\ \n",
    "x_2 - \\mu_2\n",
    "\\end{pmatrix}=\n",
    "\\begin{pmatrix}\n",
    "x_1 - \\mu_1 \\\\ \n",
    "x_2 - \\mu_2\n",
    "\\end{pmatrix}^T\n",
    "\\begin{pmatrix}\n",
    "I & 0 \\\\ \n",
    "-\\Sigma_{22}^{-1} \\Sigma_{21} & I\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    "(\\Sigma/\\Sigma_{22})^{-1} & 0 \\\\ \n",
    "0 & \\Sigma_{22}^{-1}\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    "I & -\\Sigma_{12}\\Sigma_{22}^{-1} \\\\ \n",
    "0 & I\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    "x_1 - \\mu_1 \\\\ \n",
    "x_2 - \\mu_2\n",
    "\\end{pmatrix}\n",
    "$\n",
    "\n",
    "And finally:\n",
    "\n",
    "$\n",
    "(x_2 - \\mu_1 -\\Sigma_{12}\\Sigma_{22}^{-1}(x_2-\\mu_2))^T(\\Sigma/\\Sigma_{22})^{-1}(x_2 - \\mu_1 -\\Sigma_{12}\\Sigma_{22}^{-1}(x_2-\\mu_2)) + (x_2-\\mu_2)^T\\Sigma_22^{-1}(x_2-\\mu_2)\n",
    "$\n",
    "\n",
    "And plugin back into the first Eq:\n",
    "\n",
    "$\n",
    "\\begin{split}\n",
    "p(x_1, x_2) = exp\n",
    "\\left[\n",
    "-\\frac{1}{2}\n",
    "(x_2 - \\mu_1 -\\Sigma_{12}\\Sigma_{22}^{-1}(x_2-\\mu_2))^T(\\Sigma/\\Sigma_{22})^{-1}(x_2 - \\mu_1 -\\Sigma_{12}\\Sigma_{22}^{-1}(x_2-\\mu_2)) + (x_2-\\mu_2)^T\\Sigma_22^{-1}(x_2-\\mu_2)\n",
    "\\right]\n",
    "\\end{split}\n",
    "$\n",
    "$\n",
    "\\begin{split}\n",
    "p(x_1, x_2) = exp\n",
    "\\left[\n",
    "-\\frac{1}{2}\n",
    "(x_2 - \\mu_1 -\\Sigma_{12}\\Sigma_{22}^{-1}(x_2-\\mu_2))^T(\\Sigma/\\Sigma_{22})^{-1}(x_2 - \\mu_1 -\\Sigma_{12}\\Sigma_{22}^{-1}(x_2-\\mu_2))\n",
    "\\right] \\cdot\n",
    "exp\n",
    "\\left[\n",
    "-\\frac{1}{2}\n",
    "(x_2-\\mu_2)^T\\Sigma_22^{-1}(x_2-\\mu_2)\n",
    "\\right]\n",
    "\\end{split}\n",
    "$\n",
    "\n",
    "and from the axiom of probability we obtain the follwoing equlaity:\n",
    "\n",
    "$\n",
    "\\begin{split}\n",
    "p(x_1, x_2) = p(x_1|x_2)p(x_2)= exp\n",
    "\\left[\n",
    "-\\frac{1}{2}\n",
    "(x_2 - \\mu_1 -\\Sigma_{12}\\Sigma_{22}^{-1}(x_2-\\mu_2))^T(\\Sigma/\\Sigma_{22})^{-1}(x_2 - \\mu_1 -\\Sigma_{12}\\Sigma_{22}^{-1}(x_2-\\mu_2))\n",
    "\\right] \\cdot\n",
    "exp\n",
    "\\left[\n",
    "-\\frac{1}{2}\n",
    "(x_2-\\mu_2)^T\\Sigma_22^{-1}(x_2-\\mu_2)\n",
    "\\right] = \n",
    "exp\n",
    "\\left[\n",
    "-\\frac{1}{2}\n",
    "(x_2 - \\mu_1 -\\Sigma_{12}\\Sigma_{22}^{-1}(x_2-\\mu_2))^T(\\Sigma/\\Sigma_{22})^{-1}(x_2 - \\mu_1 -\\Sigma_{12}\\Sigma_{22}^{-1}(x_2-\\mu_2))\n",
    "\\right] \\cdot\n",
    "p(x_2)\n",
    "\\end{split} \\\\ \n",
    "\\Rightarrow p(x_1|x_2) = exp\n",
    "\\left[\n",
    "-\\frac{1}{2}\n",
    "(x_2 - \\mu_1 -\\Sigma_{12}\\Sigma_{22}^{-1}(x_2-\\mu_2))^T(\\Sigma/\\Sigma_{22})^{-1}(x_2 - \\mu_1 -\\Sigma_{12}\\Sigma_{22}^{-1}(x_2-\\mu_2))\n",
    "\\right] \\\\\n",
    "\\mu_{1|2} = \\mu_1 -\\Sigma_{12}\\Sigma_{22}^{-1}(x_2-\\mu_2)\n",
    "\\Sigma_{1|2} = (\\Sigma/\\Sigma_{22})=\\Sigma_{11}-\\Sigma_{12}\\Sigma_{22}^{-1}\\Sigma_{21}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "condition_plot(nb_of_x=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://krasserm.github.io/2018/03/19/gaussian-processes/\n",
    "def kernel(X1, X2, l=1.0, sigma_f=1.0):\n",
    "    '''\n",
    "    Isotropic squared exponential kernel. Computes\n",
    "    a covariance matrix from points in X1 and X2.\n",
    "\n",
    "    Args:\n",
    "        X1: Array of m points (m x d).\n",
    "        X2: Array of n points (n x d).\n",
    "\n",
    "    Returns:\n",
    "        Covariance matrix (m x n).\n",
    "    '''\n",
    "    sqdist = np.sum(X1 ** 2, 1).reshape(-1, 1) + np.sum(X2 ** 2, 1) - 2 * np.dot(X1, X2.T)\n",
    "    return sigma_f ** 2 * np.exp(-0.5 / l ** 2 * sqdist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def posterior_predictive(X_s, X_train, Y_train, l=1.0, sigma_f=1.0, sigma_y=1e-8):\n",
    "    '''\n",
    "    Computes the suffifient statistics of the GP posterior predictive distribution\n",
    "    from m training data X_train and Y_train and n new inputs X_s.\n",
    "\n",
    "    Args:\n",
    "        X_s: New input locations (n x d).\n",
    "        X_train: Training locations (m x d).\n",
    "        Y_train: Training targets (m x 1).\n",
    "        l: Kernel length parameter.\n",
    "        sigma_f: Kernel vertical variation parameter.\n",
    "        sigma_y: Noise parameter.\n",
    "\n",
    "    Returns:\n",
    "        Posterior mean vector (n x d) and covariance matrix (n x n).\n",
    "    '''\n",
    "    K = kernel(X_train, X_train, l, sigma_f) + sigma_y ** 2 * np.eye(len(X_train))\n",
    "    K_s = kernel(X_train, X_s, l, sigma_f)\n",
    "    K_ss = kernel(X_s, X_s, l, sigma_f) + 1e-8 * np.eye(len(X_s))\n",
    "    K_inv = inv(K)\n",
    "\n",
    "    # Equation (4)\n",
    "    mu_s = K_s.T.dot(K_inv).dot(Y_train)\n",
    "\n",
    "    # Equation (5)\n",
    "    cov_s = K_ss - K_s.T.dot(K_inv).dot(K_s)\n",
    "\n",
    "    return mu_s, cov_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "noise = 0.1\n",
    "x = [-3, -2 , -1,  1, 2 , 3, 4]\n",
    "def f(x):\n",
    "    func = np.cos(x)\n",
    "    return func\n",
    "    \n",
    "gaussian_process(x, f, noise, posterior_predictive, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "noise = 0.5\n",
    "kernal = ConstantKernel(1.0) * RBF(length_scale=1.0)\n",
    "def f(x):\n",
    "    func = np.sin(x)\n",
    "    return func\n",
    "\n",
    "gaussian_process_interactive(f, noise, kernal)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
